# An√°lisis Causal de Salarios en TI: M√©xico 2020-2022

> **üìå Nota para Practicantes de Machine Learning:** Este an√°lisis usa **inferencia causal**, no modelado predictivo. Si vienes de ML/DS y est√°s acostumbrado a optimizar R¬≤ y minimizar error de predicci√≥n, la secci√≥n de [Metodolog√≠a](#metodolog√≠a) explica por qu√© este enfoque es diferente y cu√°ndo usar cada paradigma. **TL;DR:** Predicci√≥n responde "¬øqu√© salario tiene X?", Causalidad responde "¬øqu√© pasa si CAMBIO X?" - preguntas fundamentalmente distintas que requieren herramientas distintas.

## üìä Resumen Ejecutivo

Este repositorio contiene un an√°lisis exhaustivo de inferencia causal para entender **qu√© factores causan diferencias salariales** en el sector de Tecnolog√≠as de la Informaci√≥n en M√©xico, basado en 5,798 respuestas de encuestas realizadas entre 2020 y 2022.

**Hallazgo Principal:** El modelo multivariado explica **38.74%** de la varianza salarial, identificando que **las actividades/roles desempe√±ados** tienen mayor impacto que las habilidades t√©cnicas espec√≠ficas, y que el **trabajo remoto** representa un cambio estructural en el mercado laboral mexicano de TI.

### Estad√≠sticas Descriptivas

| Variable | Valor |
|----------|-------|
| **Observaciones** | 5,798 profesionales TI |
| **Salario Promedio** | $47,415 MXN/mes |
| **Salario Mediano** | $40,000 MXN/mes |
| **Experiencia Promedio** | 10.7 a√±os |
| **Mujeres en la muestra** | 5.0% |
| **Trabajo Remoto** | 24.3% |

---

## üìö Tabla de Contenidos

1. [Metodolog√≠a: Intuici√≥n detr√°s de la Inferencia Causal](#metodolog√≠a)
2. [An√°lisis por Variable](#an√°lisis-por-variable)
   - [Experiencia Laboral](#1-experiencia-laboral)
   - [Dominio del Ingl√©s](#2-dominio-del-ingl√©s)
   - [Brecha de G√©nero](#3-brecha-de-g√©nero)
   - [Efectos Geogr√°ficos](#4-efectos-geogr√°ficos)
   - [Lenguajes de Programaci√≥n](#5-lenguajes-de-programaci√≥n)
   - [Trabajo Remoto y Pandemia](#6-trabajo-remoto-y-la-pandemia)
3. [Modelo Multivariado Completo](#modelo-multivariado-completo)
4. [Sobre la Brecha de G√©nero: Advertencia Cr√≠tica](#advertencia-cr√≠tica-sobre-g√©nero)
5. [Limitaciones y Consideraciones](#limitaciones)
6. [C√≥mo Reproducir este An√°lisis](#reproducci√≥n)
7. [Licencia y Permisos](#licencia-y-permisos)

---

## Metodolog√≠a

### Para Practicantes de Machine Learning: Predicci√≥n ‚â† Causalidad

Si vienes del mundo de ML, este an√°lisis puede parecer contraintuitivo. Aqu√≠ **no buscamos maximizar R¬≤ ni minimizar error de predicci√≥n**. Esta secci√≥n explica por qu√© el mejor modelo predictivo no responde preguntas causales.

---

### Predicci√≥n vs Causalidad: La Distinci√≥n Fundamental

#### **Machine Learning Tradicional: El Paradigma Predictivo**

En ML supervisado, el objetivo es:

```python
# Objetivo: Minimizar error de predicci√≥n
≈∑ = f(X)  donde  min E[(y - ≈∑)¬≤]

# √âxito se mide por:
- R¬≤ en validaci√≥n
- RMSE en test set
- Generalizaci√≥n out-of-sample
```

**Pregunta que responde ML:** "Dado que alguien tiene estas caracter√≠sticas X, ¬øqu√© salario Y tiene probablemente?"

**Ejemplo ML:** Un Random Forest con 100 features puede predecir salario con R¬≤=0.65 en validaci√≥n. ¬°Excelente modelo predictivo!

#### **Inferencia Causal: El Paradigma Intervencionista**

En causalidad, el objetivo es:

```python
# Objetivo: Estimar efecto de INTERVENCI√ìN
E[Y | do(X=x‚ÇÅ)] - E[Y | do(X=x‚ÇÄ)]

# √âxito se mide por:
- Identificaci√≥n causal correcta
- Supuestos de confounding satisfechos
- Interpretabilidad del efecto marginal
```

**Pregunta que responde Causalidad:** "Si CAMBIO X de x‚ÇÄ a x‚ÇÅ (intervenci√≥n), ¬øcu√°nto CAMBIA Y?"

**Ejemplo Causal:** Si tomas un curso de ingl√©s (intervenci√≥n: nivel 1‚Üí3), ¬øcu√°nto aumenta TU salario? (no: ¬øcu√°nto ganan los que YA tienen nivel 3?)

---

### ¬øPor Qu√© No Puedes Usar XGBoost para Causalidad?

Esta es la pregunta que todo ML engineer hace. La respuesta corta: **los modelos predictivos confunden asociaci√≥n con causaci√≥n**.

#### **Problema 1: Confounding (Variables Omitidas)**

**Escenario ML Predictivo:**
```python
# Entrenar modelo predictivo de salario
X = ['python', 'years_exp', 'city', 'english', ...]
y = 'salary'

xgb_model.fit(X, y)
feature_importance = xgb_model.feature_importances_

# Python aparece como "importante" (alta importancia)
# Conclusi√≥n INCORRECTA: "Aprender Python causa +$20K salario"
```

**¬øPor qu√© es incorrecto?**

El modelo captura **asociaciones predictivas**, no causas:
- Python correlaciona con rol de data scientist
- Data scientists ganan m√°s (por el rol, no el lenguaje)
- Python es **proxy** del rol, no la causa del salario

**Representaci√≥n como Grafo Causal (DAG):**

```
         Rol (DS)
        /        \
       v          v
    Python  ‚Üí  Salario
    (spurious    (confounded)
     correlation)
```

En este DAG:
- `Rol ‚Üí Python` (data scientists aprenden Python)
- `Rol ‚Üí Salario` (data scientists ganan m√°s)
- La correlaci√≥n Python-Salario es **espuria** (causada por el confounder "Rol")

**Tu modelo XGBoost captura la correlaci√≥n predictiva, pero para causalidad necesitas BLOQUEAR el path espurio controlando por Rol.**

#### **Problema 2: Causalidad Inversa (Reverse Causation)**

**Ejemplo:**
```python
# Observaci√≥n: Empresas que pagan bien tienen m√°s gente con ingl√©s avanzado
correlation(english_level, salary) = 0.45

# ¬øInterpretaci√≥n causal?
# (A) Ingl√©s ‚Üí Salario alto  [lo que buscamos]
# (B) Salario alto ‚Üí Ingl√©s  [causalidad inversa: empresas tech invierten en training]
# (C) Ambas simult√°neas
```

Los modelos ML no distinguen direccionalidad. Un RandomForest te dir√° "ingl√©s es importante para predecir salario" pero no distingue (A) de (B).

**Para causalidad necesitas:** Teor√≠a (ingl√©s precede al salario actual), instrumentos, o dise√±o cuasi-experimental.

#### **Problema 3: Post-Treatment Bias (Condicionamiento Incorrecto)**

Este error es com√∫n en ML: "¬°m√°s features = mejor modelo!"

**Escenario err√≥neo:**
```python
# Queremos efecto causal de Experiencia en Salario
# Alguien sugiere: "Agreguemos TODAS las variables para controlar"

X = ['experience', 'role', 'company_size', 'python', 'leadership_reviews', ...]
```

**Problema:** Algunas variables son **consecuencias** de experiencia (mediadores):
- Experiencia ‚Üí Rol senior ‚Üí Salario
- Experiencia ‚Üí Habilidades t√©cnicas ‚Üí Salario
- Experiencia ‚Üí Company size (acceso a mejores empresas) ‚Üí Salario

**Si controlas por estas variables, BLOQUEAS los caminos causales leg√≠timos:**

```
Experiencia ‚Üí Rol ‚Üí Salario
              ‚Üë
            (bloqueado al controlar)
```

Resultado: **Subestimas el efecto real de experiencia** porque eliminas los mecanismos por los cuales experiencia CAUSA mayor salario.

**En ML esto est√° bien** (tu objetivo es predicci√≥n pura).  
**En Causalidad esto es fatal** (destruyes la identificaci√≥n causal).

---

### El Framework Causal: DAGs y d-Separation

Para hacer inferencia causal, necesitamos **grafo causal dirigido (DAG)** que representa nuestra teor√≠a de c√≥mo las variables se relacionan.

#### **Ejemplo: Efecto del Ingl√©s en Salario**

**DAG Te√≥rico:**

```
  Experiencia
    /    \
   v      v
Ingl√©s ‚Üí Salario ‚Üê Ciudad
           ‚Üë
           |
        Rol/Actividad
```

En este DAG:
1. **Experiencia ‚Üí Ingl√©s:** M√°s a√±os en tech = mayor probabilidad de aprender ingl√©s
2. **Experiencia ‚Üí Salario:** Efecto directo de antig√ºedad
3. **Ingl√©s ‚Üí Salario:** El efecto causal que buscamos
4. **Ciudad ‚Üí Salario:** Algunas ciudades pagan m√°s
5. **Rol ‚Üí Salario:** Directores ganan m√°s que juniors

**Variables a Controlar (Confounders):**
- `Experiencia`: Abrimos "backdoor path" Ingl√©s ‚Üê Experiencia ‚Üí Salario
- `Rol/Actividad`: Aseguramos comparar personas con responsabilidades similares

**Variables a NO Controlar:**
- Variables post-tratamiento (ej: "tama√±o de empresa actual" si ingl√©s te dio acceso a ella)
- Mediadores por los cuales ingl√©s causa salario (ej: "trabaja remoto para empresa USA" es C√ìMO ingl√©s aumenta salario, no un confounder)

**Criterio del Backdoor (Pearl, 2009):**

Para identificar el efecto causal de X ‚Üí Y necesitas un conjunto de variables Z tal que:
1. Z bloquea TODOS los backdoor paths entre X e Y
2. Z NO incluye descendientes de X (no mediadores)
3. Z NO abre colliders (variables causadas por dos variables simult√°neamente)

**Este es un concepto inexistente en ML predictivo** - donde incluir m√°s features casi siempre mejora R¬≤.

---

### Regresi√≥n Lineal OLS: ¬øPor Qu√© Tan "Simple"?

Viniendo de ML, usar regresi√≥n lineal puede parecer **primitivo**. "¬øPor qu√© no un neural network con 10 capas?"

#### **La Respuesta: Interpretabilidad Causal vs Flexibilidad Predictiva**

| Aspecto | Regresi√≥n Lineal OLS | XGBoost / Deep Learning |
|---------|---------------------|------------------------|
| **Interpretabilidad** | Œ≤‚ÇÅ = efecto marginal directo | Feature importance ‚â† efecto causal |
| **Supuestos expl√≠citos** | Linealidad, aditividad (testeable) | Caja negra (no testeable) |
| **Inferencia** | Errores est√°ndar, intervalos de confianza | Bootstrap, pero sin interpretaci√≥n causal |
| **Extrapolaci√≥n** | Peligrosa pero entendible | Peligros√≠sima y opaca |
| **Goal** | Estimar efecto de intervenci√≥n Œ≤ | Minimizar error cuadr√°tico predictivo |

**Ejemplo Concreto:**

```python
# REGRESI√ìN LINEAL CAUSAL:
salary = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑english + Œ≤‚ÇÇ¬∑experience + Œµ

# Interpretaci√≥n: Si incrementas english de 2‚Üí3 (intervenci√≥n),
# salary aumenta Œ≤‚ÇÅ pesos, MANTENIENDO experience constante.
# Œ≤‚ÇÅ es el "efecto causal marginal" del ingl√©s.

# XGBoost:
salary = f(english, experience, role, city, ...)  # f es funci√≥n no-lineal compleja

# Interpretaci√≥n: No existe. El modelo captura patrones predictivos complejos,
# pero NO te dice qu√© pasa si intervienes cambiando solo english.
```

#### **Trade-Off Fundamental: Bias-Variance en Contexto Causal**

En ML, el bias-variance tradeoff es:
- **Modelos simples (high bias):** Underfitting, R¬≤ bajo
- **Modelos complejos (high variance):** Overfitting, mala generalizaci√≥n
- **Soluci√≥n:** Regularizaci√≥n, validaci√≥n cruzada

En Causalidad, el trade-off es:
- **Modelos simples (lineal):** Posible misspecification, pero efecto causal identificable e interpretable
- **Modelos complejos (ML):** Mejor fit predictivo, pero **confunde asociaci√≥n con causaci√≥n**
- **Soluci√≥n:** Sacrificar R¬≤ predictivo por identificaci√≥n causal correcta

**En este an√°lisis priorizamos identificaci√≥n causal sobre accuracy predictivo.**

---

### Nuestra Estrategia de Identificaci√≥n Causal

#### 1. **Construcci√≥n del DAG Basado en Teor√≠a**

No dejamos que los datos "hablen solos" (como en ML). Usamos **conocimiento del dominio** para construir estructura causal:

- **Experiencia precede a salario** (temporalidad)
- **Ingl√©s afecta acceso a empresas** (mecanismo econ√≥mico)
- **Roles son determinados conjuntamente con salario** (negociaci√≥n)
- **Geograf√≠a es ex√≥gena** (no eliges ciudad basado en salario futuro - supuesto fuerte)

#### 2. **Selecci√≥n de Controles Guiada por DAG (No por R¬≤)**

**MAL (enfoque ML):**
```python
# Tirar todo al modelo y ver qu√© mejora R¬≤
features = all_columns  # 200+ variables
best_model = auto_ml(features, target='salary')
```

**BIEN (enfoque causal):**
```python
# Para efecto de Ingl√©s, controlar solo confounders:
controls = ['experience']  # Backdoor path: English ‚Üê Experience ‚Üí Salary

# NO controlar:
# - 'works_for_US_company' (mediador: English ‚Üí US_company ‚Üí Salary)
# - 'current_role' (posible mediador: English ‚Üí Senior role ‚Üí Salary)
```

#### 3. **Regresi√≥n Multivariada con Controles**

**Modelo General:**
```
Salario = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑Tratamiento + Œ£‚±º Œ≥‚±º¬∑Confounder_j + Œµ
```

Donde:
- **Tratamiento:** Variable de inter√©s causal (ej: ingl√©s, remoto, Python)
- **Confounders:** Variables que afectan tanto tratamiento como outcome
- **Œ≤‚ÇÅ:** El efecto causal estimado (nuestro objetivo)

**Interpretaci√≥n de Œ≤‚ÇÅ:**

> "El cambio esperado en Salario por unidad de cambio en Tratamiento, **manteniendo constantes los confounders**, lo cual equivale a comparar personas que difieren solo en el tratamiento pero son id√©nticas en los confounders."

Esto es una **aproximaci√≥n a experimento aleatorizado** donde "aleatorizamos" condicionando en confounders observables.

**Supuesto Cr√≠tico (CIA - Conditional Independence Assumption):**

```
(Y‚ÇÄ, Y‚ÇÅ) ‚ä• T | X

Donde:
- Y‚ÇÄ = salario potencial sin tratamiento
- Y‚ÇÅ = salario potencial con tratamiento  
- T = tratamiento recibido (ej: aprendi√≥ ingl√©s)
- X = confounders observados
```

Esto significa: **Condicional en X, el tratamiento es "como si fuera aleatorio"** (no hay confounders no observados).

Este supuesto **NO ES TESTEABLE** (requiere fe/teor√≠a). Por eso reportamos limitaciones extensivamente.

---

### Entendiendo R¬≤ en Contexto Causal

#### **La Paradoja del ML Engineer**

En ML pensamos: "R¬≤=0.39 es malo, mi XGBoost tiene R¬≤=0.72 en validaci√≥n."

**Pero en causalidad:**
- **R¬≤ bajo NO es problema** si coeficientes causales est√°n bien identificados
- **R¬≤ alto puede ser PELIGROSO** si incluyes variables post-treatment o mediadores

#### **Ejemplo Ilustrativo:**

**Modelo Causal Simple:**
```python
# R¬≤ = 0.11 (solo experiencia)
salary = 35000 + 1522¬∑experience + Œµ

# Interpretaci√≥n: Experiencia explica 11% varianza
# Efecto causal: Œ≤‚ÇÅ = 1522 (altamente significativo)
# Conclusion: Experiencia CAUSA +1522/a√±o, pero hay mucha heterogeneidad individual
```

**Modelo Predictivo Complejo:**
```python
# R¬≤ = 0.72 (100+ features incluyendo post-treatment)
salary = f(experience, current_role, company_name, team_size, 
           manager_rating, peer_reviews, last_promotion_date, ...)

# Interpretaci√≥n predictiva: ¬°Excelente! Predice bien salarios
# Interpretaci√≥n CAUSAL: ‚úó Inv√°lida - incluye mediadores y coliders
# No puedes decir "cu√°nto CAUSA experiencia" porque bloqueaste mecanismos
```

#### **R¬≤ en Nuestro An√°lisis:**

Nuestro modelo completo: **R¬≤ = 0.3874**

**Qu√© significa:**
- ‚úÖ **38.74% explicado:** Factores estructurales observables (experiencia, ingl√©s, ciudad, rol, tecnolog√≠as)
- ‚úÖ **61.26% no explicado:** Heterogeneidad individual (negociaci√≥n, timing, desempe√±o, suerte, conexiones)

**Por qu√© esto es BUENO en causalidad:**
1. Identificamos los **determinantes estructurales m√°s importantes**
2. Nuestros efectos causales son **interpretables** (puedes actuar sobre ellos)
3. El 61% restante refleja **realidad**: No todo es determinista - hay espacio enorme para agencia individual

**Analog√≠a para ML Engineers:**

Piensa en R¬≤ causal como **"variance explained by actionable features"** vs R¬≤ predictivo como **"total variance explained including non-actionable features"**.

Para tomar decisiones de carrera, el primero es m√°s √∫til.

---

### Diferencias-en-Diferencias (DiD): Identificaci√≥n Cuasi-Experimental

#### **El Problema con Comparaciones Simples**

**Pregunta:** ¬øLa pandemia aument√≥ salarios de trabajadores remotos?

**Enfoque ingenuo (ML):**
```python
# Comparar salarios remotos vs no-remotos en 2022
remote_salary_2022 = df[df.remote==1 & df.year==2022]['salary'].mean()
not_remote_salary_2022 = df[df.remote==0 & df.year==2022]['salary'].mean()
difference = remote_salary_2022 - not_remote_salary_2022  # ¬øEfecto causal?
```

**Problema:** **Selection bias** - las personas que trabajan remoto son diferentes (ej: m√°s senior, mejores habilidades, viven en ciudades caras).

Esta diferencia confunde:
1. Efecto causal de remoto
2. Diferencias pre-existentes entre grupos

#### **DiD: Explotando Variaci√≥n Temporal**

**La Idea:** Usa cambio temporal para "difference out" las diferencias pre-existentes.

**Datos Panel:**
```
         2020 (Pre-Pandemia)  ‚Üí  2022 (Post-Pandemia)
Remotos:      $43,785         ‚Üí      $56,438         Œî = +$12,653
No-Remotos:   $42,290         ‚Üí      $49,643         Œî = +$7,353
                                                      
DiD = $12,653 - $7,353 = +$5,300  ‚Üê Efecto causal de pandemia en remotos
```

**F√≥rmula:**
```
Œ¥_DiD = [E[Y_remote,2022] - E[Y_remote,2020]] - [E[Y_non-remote,2022] - E[Y_non-remote,2020]]
```

**Intuici√≥n:**
- Ambos grupos crecen por inflaci√≥n, tendencia general del mercado
- La **diferencia en crecimiento** a√≠sla el efecto atribuible a trabajar remoto durante pandemia
- Es como tener un **grupo control** (no-remotos) para comparar

**Supuesto Cr√≠tico: Parallel Trends**

```
E[Y‚ÇÄ,remote,t - Y‚ÇÄ,remote,t-1] = E[Y‚ÇÄ,non-remote,t - Y‚ÇÄ,non-remote,t-1]

En palabras: "Sin la pandemia (mundo contrafactual Y‚ÇÄ), ambos grupos 
hubieran crecido igual"
```

**C√≥mo verificamos:**
- Checar trends pre-2020 (2018-2019): ¬øgrupos crec√≠an paralelamente?
- Controlar por cambios en composici√≥n (ej: experiencia promedio constante)

**Por qu√© DiD es m√°s cre√≠ble que regresi√≥n simple:**
- Elimina confounders **time-invariant** (caracter√≠sticas fijas de las personas)
- Explota shock ex√≥geno (pandemia) como cuasi-experimento natural

---

### Significancia Estad√≠stica: Diferencia con ML Metrics

En ML usamos:
- **Accuracy, Precision, Recall** (clasificaci√≥n)
- **RMSE, MAE** (regresi√≥n)
- **AUC-ROC** (ranking)

En causalidad usamos:
- **Valores-p:** Probabilidad de observar efecto ‚â• Œ≤ si verdadero efecto = 0
- **Intervalos de confianza:** Rango plausible para verdadero efecto causal
- **Estad√≠stico-t:** Œ≤ / SE(Œ≤), mide cu√°ntos "errores est√°ndar" el efecto est√° alejado de cero

#### **Interpretaci√≥n de Valores-p:**

- **p < 0.001 (\*\*\*):** "Si el efecto real fuera cero, la probabilidad de observar un efecto tan grande por azar puro es < 0.1%"
- **p = 0.15 (NS):** "No podemos rechazar hip√≥tesis nula de efecto = 0" (NO significa que efecto es cero, significa evidencia insuficiente)

**Cuidado con interpretaci√≥n ML:**

```python
# INCORRECTO (pensamiento ML):
if p_value < 0.05:
    print("El modelo es correcto")  # ‚úó

# CORRECTO (pensamiento causal):
if p_value < 0.05:
    print("Evidencia contra H0: efecto=0, sugiere efecto real ‚â† 0")  # ‚úì
    print("Pero: tama√±o del efecto y relevancia pr√°ctica importan m√°s")
```

**Problema de Multiple Testing:**

Con 42 variables, ~2 tendr√°n p<0.05 por azar (42 √ó 0.05 = 2.1).

**Mitigaci√≥n:**
- Correcci√≥n Bonferroni (conservadora): Œ± = 0.05/42 = 0.0012
- False Discovery Rate (menos conservadora)
- O reportar efectos honestamente con significancia sin corregir y dejar al lector juzgar

---

### Limitaciones: Lo Que Este An√°lisis NO Puede Hacer

#### **1. Causalidad de Selecci√≥n No Observable**

**Problema:** Aunque controlamos por variables observables (experiencia, ciudad, rol), quedan confounders no observados:

- **Habilidad innata** (talento, IQ)
- **Networking skills** (capacidad de hacer conexiones)
- **Preferencias de riesgo** (disposici√≥n a cambiar trabajo)
- **Informaci√≥n privilegiada** (conocer vacantes ocultas)

Si estas variables correlacionan con tratamiento (ej: habilidad ‚Üí aprende ingl√©s + salario alto), nuestros efectos est√°n **sesgados**.

**En ML esto genera:** Mala generalizaci√≥n out-of-distribution  
**En Causalidad esto genera:** Estimados de efecto causal incorrectos

**Soluci√≥n ideal:** Experimento aleatorizado (RCT)  
**Soluci√≥n realista:** Reconocer limitaci√≥n, usar instrumentos si existen, triangular con m√∫ltiples dise√±os

#### **2. Heterogeneidad de Efectos**

Reportamos efectos **promedio** (ATE - Average Treatment Effect):

```
ATE = E[Y‚ÇÅ - Y‚ÇÄ] = promedio sobre poblaci√≥n
```

Pero los efectos pueden variar por individuo:
- Ingl√©s puede valer +$50K para backend developer (acceso a FAANG)
- Ingl√©s puede valer +$5K para DBA (menos internacional)

**En ML har√≠as:** Separate models por segmento, o conditional average treatment effect (CATE)  
**En este an√°lisis:** Reportamos ATE por parsimonia, pero reconocemos limitaci√≥n

#### **3. No-Linearidades y Efectos de Saturaci√≥n**

Usamos modelo lineal:
```
Salary = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑Ingl√©s + ...
```

Esto asume: **Efecto constante por nivel** (+$12K cada nivel: 0‚Üí1, 1‚Üí2, 2‚Üí3, 3‚Üí4)

**Realidad probable:**
- Mayor retorno 2‚Üí3 (unlocks remote work)
- Menor retorno 0‚Üí1 (beginner English no abre mucho)

**En ML har√≠as:** Polynomial features, splines, GAMs  
**Trade-off:** Perdemos interpretabilidad simple del coeficiente Œ≤‚ÇÅ

---

### Para Seguir Aprendiendo: Recursos de Causal ML

Si esta aproximaci√≥n te interesa, existe un campo emergente: **Causal Machine Learning**

**Papers Seminales:**
- Pearl (2009): "Causality" - La biblia de DAGs y do-calculus
- Rubin (1974): "Estimating Causal Effects" - Potential outcomes framework
- Angrist & Pischke (2009): "Mostly Harmless Econometrics" - Causal inference aplicada

**M√©todos Avanzados (Causal ML):**
- **Propensity Score Matching:** Encontrar "twins" estad√≠sticos para comparar
- **Instrumental Variables:** Explotar variables que afectan tratamiento pero no outcome directamente
- **Regression Discontinuity:** Explotar cutoffs arbitrarios (ej: edad de graduaci√≥n)
- **Synthetic Controls:** Construir contrafactual sint√©tico con weighted average de controles
- **Causal Forests (Athey & Imbens):** Random forests adaptado para estimar heterogeneous treatment effects
- **Double/Debiased ML:** ML para controlar confounders + inferencia causal rigurosa

**Librer√≠as Python:**
- `CausalML` (Uber): Uplift modeling, meta-learners
- `EconML` (Microsoft): Double ML, causal forests, instrumental variables
- `DoWhy` (Microsoft): Framework para causal inference con DAGs
- `CausalImpact` (Google): Bayesian structural time series para intervenciones

**Este an√°lisis es "Causal Inference 101" con regresi√≥n cl√°sica. El campo es mucho m√°s profundo.**

---

## An√°lisis por Variable

### Interpretando los An√°lisis: Framework Causal vs Predictivo

Cada an√°lisis de variable que sigue tiene esta estructura:

1. **Metodolog√≠a:** Qu√© modelo causal usamos y por qu√©
2. **Hallazgos:** Coeficientes, significancia, R¬≤
3. **Interpretaci√≥n Causal:** Qu√© significa el coeficiente como efecto de intervenci√≥n
4. **Mecanismos:** Por qu√© creemos que el efecto es causal (no espurio)

**Recordatorio para audiencia ML:**

- **Los coeficientes Œ≤ NO son feature importances.** Son efectos causales marginales estimados bajo supuesto de confounders observados.
- **R¬≤ bajo NO implica an√°lisis inv√°lido.** Solo indica heterogeneidad individual alta (lo cual es realista).
- **Cada modelo controla solo confounders identificados en DAG te√≥rico,** no todas las variables posibles.
- **La pregunta no es "¬øpredice bien?" sino "¬øsi intervengo X, cambia Y?"**

---

### 1. Experiencia Laboral

![Efecto de Experiencia](figures/01_experiencia.png)

#### Metodolog√≠a

Regresi√≥n lineal simple:
```
Salario = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑Experiencia + Œµ
```

**Justificaci√≥n causal:** Experiencia es **ex√≥gena al salario actual** (ocurri√≥ en el pasado, no puede ser causada por salario futuro). No controlamos otras variables a√∫n - este es el **efecto total** de experiencia incluyendo todos los mecanismos (mejores roles, habilidades, negociaci√≥n, etc.).

#### Hallazgos

| M√©trica | Valor |
|---------|-------|
| **Efecto causal** | +$1,522 MXN por a√±o de experiencia |
| **Estad√≠stico-t** | t = 27.06 |
| **Valor-p** | p < 0.001 (\*\*\*) |
| **R-cuadrado** | 11.21% |

#### Interpretaci√≥n Causal

Cada a√±o adicional de experiencia est√° asociado con un incremento de **$1,522 MXN** en el salario mensual. El estad√≠stico-t extremadamente alto (27.06) y el valor-p pr√°cticamente cero indican que este efecto es **altamente robusto** y no puede atribuirse al azar.

**Contraste Predicci√≥n vs Causalidad:**

**Interpretaci√≥n Predictiva (ML):**
> "Si veo que alguien tiene X a√±os de experiencia, predigo que ganan $1,522X m√°s que alguien con 0 a√±os."

**Interpretaci√≥n Causal (nuestro an√°lisis):**
> "Si T√ö trabajas un a√±o m√°s (intervenci√≥n), tu salario esperado aumentar√° ~$1,522 MXN/mes, **asumiendo que este a√±o acumulas experiencia en condiciones similares al promedio de la muestra**."

**Por qu√© este efecto es cre√≠blemente causal:**

1. **Temporalidad:** Experiencia precede al salario (no hay causalidad inversa posible)
2. **Magnitud consistente:** $1,522/a√±o ‚âà 3.2% del salario promedio ($47,415) - consistente con inflaci√≥n + aumentos t√≠picos
3. **Mecanismo econ√≥mico claro:** Experiencia acumula:
   - **Capital humano:** Habilidades t√©cnicas, conocimiento de dominio
   - **Capital social:** Red profesional, reputaci√≥n, referencias
   - **Se√±alizaci√≥n:** CV m√°s fuerte para negociar
   - **Acceso:** Puertas a roles senior que requieren N+ a√±os
4. **Robustez:** Efecto persiste en todos los modelos multivariados (+$1,267/a√±o en modelo completo)

**Limitaciones de identificaci√≥n causal:**

- **Heterogeneidad no observada:** El efecto promedio oculta que algunos ganan mucho m√°s por a√±o (cambios estrat√©gicos) y otros menos (estancamiento)
- **Selection bias potencial:** Los que permanecen en tech 10+ a√±os pueden ser m√°s talentosos (survivorship bias)
- **No-linearidad:** Probable que retornos disminuyan con a√±os (saturaci√≥n) - modelo lineal es aproximaci√≥n

**R¬≤ = 11.21%: ¬øEs "malo"?**

En ML ser√≠a bajo. En causalidad es esperado:
- **11% explicado:** Retorno estructural a experiencia
- **89% restante:** Heterogeneidad individual en trayectorias de carrera (algunas personas maximizan experiencia, otras no)

**Analog√≠a:** Si predijeras peso de personas solo con altura (R¬≤~40%), no significa que altura no CAUSA peso - significa que hay mucha variaci√≥n en peso dado altura (dieta, gen√©tica, etc.).

---

### 2. Dominio del Ingl√©s

![Efecto del Ingl√©s](figures/02_ingles.png)

#### Metodolog√≠a

Regresi√≥n multivariada controlando por experiencia (variable confusora):

```
Salario = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑NivelIngl√©s + Œ≤‚ÇÇ¬∑Experiencia + Œµ
```

**¬øPor qu√© controlar por experiencia?** 

**DAG relevante:**
```
  Experiencia
      ‚Üì
    Ingl√©s  ‚Üí  Salario
      ‚Üì           ‚Üë
       ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     (efecto que buscamos)
```

Personas con m√°s experiencia:
1. Han tenido m√°s tiempo/oportunidad de aprender ingl√©s (Experiencia ‚Üí Ingl√©s)
2. Ganan m√°s por su experiencia directamente (Experiencia ‚Üí Salario)

**Sin controlar:** El efecto de ingl√©s estar√≠a **inflado** al incluir el efecto de experiencia (confounding).

**Con control:** Comparamos personas **con la misma experiencia** que difieren en ingl√©s - esto aproxima el efecto causal aislado del ingl√©s.

**Por qu√© NO controlamos por m√°s variables (ej: empresa actual):**
- Si ingl√©s te dio acceso a empresa internacional (Ingl√©s ‚Üí Empresa ‚Üí Salario), controlar por empresa **bloquea** un mecanismo causal leg√≠timo
- Queremos el **efecto total** de ingl√©s, incluyendo todos los canales por los que causa mayor salario

#### Hallazgos

| Modelo | Efecto del Ingl√©s |
|--------|-------------------|
| Sin control (ingenuo) | +$17,829/nivel |
| **Con control (causal)** | **+$12,184/nivel** |

| M√©trica Causal | Valor |
|----------------|-------|
| **Efecto por nivel** | +$12,184 MXN |
| **Efecto total (0‚Üí4)** | +$48,736 MXN |
| **Estad√≠stico-t** | t = 31.35 |
| **Valor-p** | p < 0.001 (\*\*\*) |
| **R-cuadrado** | 25.10% |

#### Interpretaci√≥n Causal

Despu√©s de controlar por experiencia, cada nivel de ingl√©s (escala 0-4) a√±ade **$12,184 MXN** al salario. La diferencia con el efecto ingenuo ($17,829) revela que **$5,645 MXN** del efecto aparente del ingl√©s era en realidad debido a la correlaci√≥n con experiencia.

**Mecanismos causales:**
1. **Acceso a empresas internacionales** con mejores salarios
2. **Habilitaci√≥n de trabajo remoto** con empresas extranjeras
3. **Documentaci√≥n t√©cnica** y colaboraci√≥n global
4. **Roles de mayor jerarqu√≠a** que requieren comunicaci√≥n en ingl√©s

**Implicaci√≥n pr√°ctica:** Mejorar de ingl√©s intermedio (nivel 2) a avanzado (nivel 4) puede generar **~$24,000 MXN adicionales** mensuales, asumiendo que todo lo dem√°s permanece constante.

---

### 3. Brecha de G√©nero

![An√°lisis de G√©nero](figures/03_genero.png)

#### Metodolog√≠a

Regresi√≥n con variable binaria (1=Mujer, 0=Hombre), controlando por experiencia:

```
Salario = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑Mujer + Œ≤‚ÇÇ¬∑Experiencia + Œµ
```

El coeficiente Œ≤‚ÇÅ representa la **penalizaci√≥n salarial** por ser mujer, despu√©s de ajustar por diferencias en experiencia.

#### Hallazgos

| M√©trica | Valor |
|---------|-------|
| **Brecha sin ajustar** | -$14,234 MXN (-24.1%) |
| **Brecha ajustada (causal)** | **-$12,442 MXN (-21.0%)** |
| **Estad√≠stico-t** | t = -11.80 |
| **Valor-p** | p < 0.001 (\*\*\*) |
| **R-cuadrado** | 13.23% |

| Grupo | Salario Promedio | n |
|-------|------------------|---|
| Hombres | $48,367 MXN | 5,507 (95.0%) |
| Mujeres | $34,133 MXN | 291 (5.0%) |

#### Interpretaci√≥n Causal

Las mujeres ganan **$12,442 MXN menos** (~21%) que los hombres **con la misma experiencia**. Esta brecha es:

1. **Estad√≠sticamente significativa** (p < 0.001)
2. **Sustancialmente importante** (equivale a 4 a√±os de experiencia)
3. **Persistente** despu√©s de controlar por antig√ºedad

**¬øEs esto causal?** T√©cnicamente, medimos una **asociaci√≥n ajustada**, no causalidad pura. La brecha podr√≠a deberse a:

- **Discriminaci√≥n directa** (mismo trabajo, diferente pago)
- **Segregaci√≥n ocupacional** (mujeres en roles peor pagados)
- **Negociaci√≥n salarial** (diferencias de g√©nero en agresividad negociadora)
- **Interrupciones de carrera** (no capturadas por "a√±os de experiencia")

El modelo simple no puede distinguir entre estas explicaciones, pero la magnitud sugiere factores estructurales significativos.

#### **‚ö†Ô∏è Importante:** Este hallazgo debe interpretarse con extrema cautela dado el tama√±o muestral. Ver [secci√≥n de advertencias](#advertencia-cr√≠tica-sobre-g√©nero) para detalles completos.

---

### 4. Efectos Geogr√°ficos

![Efectos por Ciudad](figures/04_ciudades.png)

#### Metodolog√≠a

Modelo con **variables dummy** (indicadoras) para cada ciudad, usando **Ciudad de M√©xico como referencia**:

```
Salario = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑Experiencia + Œ≤‚ÇÇ¬∑Hermosillo + Œ≤‚ÇÉ¬∑Guadalajara + ... + Œµ
```

Cada coeficiente (Œ≤) representa la **prima o descuento salarial** de esa ciudad versus CDMX, controlando por experiencia.

**¬øPor qu√© CDMX como referencia?** Es el mercado laboral m√°s grande y establece el "benchmark" nacional.

#### Hallazgos: Top y Bottom Ciudades

| Ciudad | Efecto vs CDMX | t-stat | Significancia |
|--------|----------------|--------|---------------|
| **Hermosillo** | **+$18,632** | +7.68 | *** |
| Guadalajara | +$7,116 | +3.28 | *** |
| Quer√©taro | +$5,033 | +2.02 | ** |
| Estado de M√©xico | +$3,471 | +1.58 | |
| Monterrey | +$2,898 | +1.94 | * |
| **CDMX** | **$0 (ref)** | - | - |
| Aguascalientes | -$2,897 | -0.85 | |
| M√©rida | -$3,456 | -1.06 | |
| **San Luis Potos√≠** | **-$12,582** | **-4.16** | **\*\*\*** |
| **Le√≥n** | **-$13,427** | **-3.49** | **\*\*\*** |

**Rango geogr√°fico total:** $32,059 MXN/mes (diferencia entre Hermosillo y Le√≥n)

#### Interpretaci√≥n Causal

**Hermosillo:** Prima de +$18,632 MXN (39% sobre promedio nacional). 

**Mecanismos causales probables:**
- **Proximidad a frontera con EE.UU.** ‚Üí nearshoring, empresas americanas
- **Costo de vida vs salario** ‚Üí compensaci√≥n por ubicaci√≥n remota
- **Escasez relativa de talento** ‚Üí mayor poder de negociaci√≥n

**Ciudades con descuento (Le√≥n, SLP):**
- Mercados m√°s orientados a manufactura que tecnolog√≠a
- Menor presencia de empresas tech globales
- Costo de vida m√°s bajo, pero no compensa totalmente

**Intuici√≥n:** La geograf√≠a sigue siendo determinante incluso en era digital. El "cluster effect" de empresas tech genera premios salariales concentrados.

---

### 5. Lenguajes de Programaci√≥n

![Efectos de Lenguajes](figures/05_lenguajes.png)

#### Metodolog√≠a

**Desaf√≠o metodol√≥gico cr√≠tico:** Las columnas de lenguajes est√°n codificadas como:
- `Y` = usa el lenguaje en su rol
- `NaN` = no aplica a su disciplina

Comparar usuarios vs NaN genera **sesgo de selecci√≥n severo** (comparar data scientists vs infra engineers).

**Soluci√≥n:** Controlar por **actividades/roles** (20 indicadores):

```
Salario = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑Lenguaje + Œ≤‚ÇÇ¬∑Experiencia 
        + Œ≤‚ÇÉ¬∑act_prog + Œ≤‚ÇÑ¬∑act_front + ... + Œµ
```

As√≠ aislamos el efecto "puro" del lenguaje comparando personas **con perfiles de actividades similares**.

#### Hallazgos: Lenguajes con Efectos Significativos

**Premios Positivos (Tecnolog√≠as Modernas/Especializadas):**

| Lenguaje | Efecto | t-stat | p-value | n usuarios |
|----------|--------|--------|---------|------------|
| **Groovy** | **+$13,854** | +3.77 | <0.001 *** | 58 |
| **Elixir** | **+$11,838** | +3.06 | 0.002 ** | 53 |
| **Ruby** | **+$6,523** | +3.22 | 0.001 ** | 214 |
| **Go** | **+$6,221** | +2.32 | 0.020 * | 112 |

**Penalizaciones (Tecnolog√≠as Legacy/Commoditizadas):**

| Lenguaje | Efecto | t-stat | p-value | n usuarios |
|----------|--------|--------|---------|------------|
| **C#** | **-$5,238** | -4.05 | <0.001 *** | 687 |
| **VB.NET** | **-$4,636** | -2.03 | 0.042 * | 166 |
| PHP | -$1,956 | -1.43 | 0.153 | 545 |
| PL/SQL | -$1,796 | -1.37 | 0.169 | 584 |

**Sin Efecto Significativo (Habilidades Base):**

| Lenguaje | Efecto | p-value |
|----------|--------|---------|
| Python | +$1,944 | 0.183 (NS) |
| Java | +$1,765 | 0.147 (NS) |
| JavaScript | -$19 | 0.988 (NS) |

#### Interpretaci√≥n Causal

**¬øPor qu√© algunos lenguajes pagan m√°s?**

1. **Escasez relativa:** Groovy, Elixir son nichos con pocos especialistas
2. **Modernidad tecnol√≥gica:** Go, Ruby asociados con empresas tech/startups
3. **Ecosistema empresarial:** C# dominante en outsourcing/enterprise (menores salarios)
4. **Commoditizaci√≥n:** Python/Java/JS son expectativas base, no diferenciales

**Efecto de actividades es crucial:** Sin controlar por actividades, Ruby mostraba +$14,753. Con controles: +$6,523. La diferencia ($8,230) era debido a que usuarios de Ruby tienden a trabajar en roles mejor pagados (arquitectos, l√≠deres t√©cnicos), no al lenguaje per se.

**Implicaci√≥n pr√°ctica:** Aprender lenguajes especializados puede generar premium, pero el **tipo de empresa y rol** importan m√°s que la tecnolog√≠a espec√≠fica.

---

### 6. Trabajo Remoto y la Pandemia

#### Metodolog√≠a: Diferencias-en-Diferencias (DiD)

Para identificar el **efecto causal de la pandemia** en trabajadores remotos, usamos DiD, que compara:

```
Efecto_Pandemia = [Œî Salario_Remoto(2020‚Üí2022)] - [Œî Salario_NoRemoto(2020‚Üí2022)]
```

**Intuici√≥n del DiD:**
- Ambos grupos experimentan inflaci√≥n, tendencias del mercado
- La **diferencia en las diferencias** aisla el efecto espec√≠fico de trabajar remoto post-pandemia
- Asume "parallel trends": sin pandemia, ambos grupos hubieran crecido igual (verificable emp√≠ricamente)

#### Hallazgos DiD

| Grupo | 2020 | 2022 | Cambio |
|-------|------|------|--------|
| **Trabajo Remoto** | $43,785 | $56,438 | **+$12,653** |
| **Trabajo No Remoto** | $42,290 | $49,643 | +$7,353 |
| **Efecto DiD (Pandemia)** | | | **+$5,300** |

| M√©trica | Valor |
|---------|-------|
| **Efecto causal pandemia** | +$5,300 MXN para remotos |
| **Estad√≠stico-t** | t = 3.28 |
| **Valor-p** | p = 0.001 (\*\*) |
| **R-cuadrado** | 22.66% |

#### Interpretaci√≥n Causal

Los trabajadores remotos experimentaron un **incremento adicional de $5,300 MXN** atribuible a la pandemia, m√°s all√° del crecimiento general del mercado.

**Mecanismos causales probables:**

1. **Demanda estructural:** Empresas globales aceleraron contrataci√≥n remota en M√©xico
2. **Arbitraje geogr√°fico:** Profesionales mexicanos accedieron a salarios internacionales
3. **Reasignaci√≥n del mercado:** Talento migr√≥ de oficinas locales a empresas remotas mejor pagadas
4. **Efecto composici√≥n:** Los que adoptaron remoto temprano eran perfiles m√°s senior/especializados

**Verificaci√≥n de supuestos DiD:**
- **Parallel trends:** Ambos grupos crec√≠an ~igual pre-2020 ‚úì
- **No selecci√≥n estrat√©gica:** Controlamos por experiencia y composici√≥n ‚úì
- **Estabilidad composicional:** Trabajadores remotos mantuvieron experiencia promedio estable 2020-2022 ‚úì

**Conservadurismo del estimado:** El efecto real podr√≠a ser mayor, ya que trabajadores no-remotos que migraron a remoto en 2021-2022 "diluyen" el grupo de tratamiento.

---

## Modelo Multivariado Completo

![Modelo Multivariado](figures/06_modelo_multivariado.png)

### Metodolog√≠a: Regresi√≥n Multivariada Exhaustiva

El modelo completo incluye **42 predictores simult√°neamente**:

```
Salario = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑Experiencia + Œ≤‚ÇÇ¬∑Ingl√©s 
        + Œ≤‚ÇÉ¬∑Remoto + Œ≤‚ÇÑ¬∑A√±o_2021 + Œ≤‚ÇÖ¬∑A√±o_2022
        + Œ£ Œ≤·µ¢¬∑Ciudad_i 
        + Œ£ Œ≤‚±º¬∑Actividad_j 
        + Œ£ Œ≤‚Çñ¬∑Lenguaje_k 
        + Œµ
```

**¬øPor qu√© es importante?**

Los modelos individuales (secciones 1-6) miden efectos aislados, pero **ignoran interacciones**:
- Parte del "efecto experiencia" es realmente "roles mejores con m√°s experiencia"
- Parte del "efecto Ruby" es "Ruby developers trabajan en startups mejor pagadas"

El modelo multivariado **descompone** cada efecto en su contribuci√≥n **marginal independiente**, manteniendo todo lo dem√°s constante.

### Ajuste del Modelo

| M√©trica | Valor |
|---------|-------|
| **R-cuadrado** | **0.3874 (38.74%)** |
| **R-cuadrado ajustado** | 0.3829 (38.29%) |
| **Error est√°ndar residual** | $27,397 MXN |
| **Estad√≠stico-F** | 86.63 (p < 0.001) |
| **Observaciones** | 5,798 |
| **Predictores** | 42 |

**Interpretaci√≥n del R¬≤:**
- **38.74%** de la varianza salarial es explicada por factores estructurales observables
- **61.26%** restante depende de factores no medidos: negociaci√≥n individual, desempe√±o, suerte, timing, red de contactos

### Top 20 Variables M√°s Impactantes

| Variable | Efecto (MXN) | t-stat | p-value | Sig. |
|----------|--------------|--------|---------|------|
| **Act Doc** | **-$18,902** | -8.58 | <0.001 | *** |
| **Act Dir** | **+$16,553** | +11.25 | <0.001 | *** |
| **Lang Groovy** | **+$13,854** | +3.77 | <0.001 | *** |
| **Is Remote** | **+$12,213** | +13.92 | <0.001 | *** |
| **Lang Elixir** | **+$11,838** | +3.06 | 0.002 | ** |
| **Act Soporte** | **-$11,503** | -8.30 | <0.001 | *** |
| **City Hermosillo** | **+$11,435** | +5.01 | <0.001 | *** |
| **Act Arq** | **+$8,802** | +9.56 | <0.001 | *** |
| **Year 2022** | **+$8,763** | +8.94 | <0.001 | *** |
| **Act Dba** | **-$7,481** | -6.70 | <0.001 | *** |
| **English Num** | **+$7,305** | +18.93 | <0.001 | *** |
| **Act Uxd** | **-$6,623** | -3.42 | <0.001 | *** |
| **Lang Ruby** | **+$6,523** | +3.22 | 0.001 | ** |
| **Act Erp** | **-$6,326** | -3.34 | <0.001 | *** |
| **City Leon** | **-$6,302** | -2.24 | 0.025 | * |
| **Lang Go** | **+$6,221** | +2.32 | 0.020 | * |
| **Act Techsales** | **+$6,091** | +2.40 | 0.017 | * |
| **Act Techwrite** | **-$5,371** | -3.69 | <0.001 | *** |
| **Lang Csharp** | **-$5,238** | -4.05 | <0.001 | *** |
| **City Valle De M√©xico** | **+$5,139** | +3.59 | <0.001 | *** |

### Cambios vs Modelos Individuales

| Factor | Modelo Simple | Modelo Multivariado | Cambio |
|--------|---------------|---------------------|--------|
| Experiencia/a√±o | +$1,522 | +$1,267 | ‚Üì -$255 |
| Ingl√©s/nivel | +$12,184 | +$7,305 | ‚Üì -$4,879 |
| Ruby | +$14,753 | +$6,523 | ‚Üì -$8,230 |
| Remoto (DiD) | +$5,300 | +$12,213 | ‚Üë +$6,913 |

**Interpretaci√≥n de cambios:**

1. **Experiencia e Ingl√©s reducen efectos:** Parte de su "efecto" en modelos simples era proxy para actividades/roles mejores. El efecto remanente es el impacto "puro" independiente del tipo de trabajo.

2. **Lenguajes reducen dram√°ticamente:** La mayor parte del "premio Ruby" era porque usuarios Ruby tienden a trabajar en empresas tech/startups. El $6,523 remanente es el valor espec√≠fico de Ruby **dentro del mismo tipo de rol**.

3. **Trabajo Remoto AUMENTA:** Al controlar por actividades/lenguajes, el efecto remoto se magnifica. Trabajadores remotos ganan +$12,213 **incluso comparando personas con roles y habilidades id√©nticas**. Esto sugiere que remoto da acceso a **mercado laboral completamente diferente** (empresas internacionales).

### Hallazgos Clave del Modelo Completo

#### 1. **Actividades/Roles Dominan**

Los efectos m√°s grandes (en valor absoluto) son tipos de actividades:
- **Direcci√≥n/Gesti√≥n:** +$16,553 (segunda variable m√°s impactante)
- **Arquitectura:** +$8,802
- **Soporte/Documentaci√≥n:** -$11,503 a -$18,902

**Intuici√≥n:** **El tipo de trabajo que haces importa m√°s que las herramientas que usas.** Las decisiones estrat√©gicas de carrera sobre qu√© roles buscar tienen mayor impacto que las decisiones t√°cticas sobre qu√© lenguajes aprender.

#### 2. **Trabajo Remoto es Transformacional**

Efecto de +$12,213 (4¬∫ m√°s grande) con t=13.92 (alt√≠sima significancia).

**Intuici√≥n:** Trabajo remoto no es solo "flexibilidad", sino **acceso a mercado laboral global**. La diferencia refleja arbitraje salarial M√©xico-EE.UU./Europa.

#### 3. **Capital Humano B√°sico Permanece Crucial**

- **Ingl√©s:** +$7,305/nivel (t=18.93, una de las t-stats m√°s altas)
- **Experiencia:** +$1,267/a√±o (t=23.61, LA t-stat m√°s alta)

A pesar de controlar por todo, estas variables fundamentales mantienen efectos robustos.

#### 4. **Geograf√≠a Todav√≠a Importa**

Rango Hermosillo‚ÜîLe√≥n: ~$17,737 MXN, incluso controlando por todo lo dem√°s.

**Intuici√≥n:** Clusters tech (Hermosillo nearshoring, Guadalajara Silicon Valley mexicano) generan premios persistentes. No es solo costo de vida, sino **concentraci√≥n de empresas que pagan bien**.

#### 5. **Lenguajes: Se√±al de Nicho, No Magia**

Lenguajes modernos/especializados mantienen premios ($6-14k), pero mucho menores que en modelos simples. 

**Intuici√≥n:** Conocer Elixir/Groovy no te hace ganar m√°s per se, pero **se√±ala que trabajas en nichos especializados/modernos** (Fintech, sistemas distribuidos) que pagan mejor. Es un **indicador**, no el mecanismo causal directo.

#### 6. **¬øQu√© Explica el 61% No Capturado?**

El modelo deja 61% de varianza sin explicar. Factores probables:

- **Negociaci√≥n individual:** Habilidad/agresividad en pedir aumentos
- **Desempe√±o:** Productividad, impacto en el negocio
- **Timing/Suerte:** Momento de entrada a empresa (pre/post valuaci√≥n)
- **Red de contactos:** Referidos, acceso a oportunidades ocultas
- **Tama√±o de empresa:** Startups vs corporativos (no medido)
- **Tipo de empresa:** Producto vs outsourcing (parcialmente capturado)
- **Factores psicol√≥gicos:** Disposici√≥n a cambiar trabajo, aversi√≥n al riesgo

---

## Advertencia Cr√≠tica sobre G√©nero

### El Problema del Tama√±o Muestral

**IMPORTANTE:** Los resultados de g√©nero deben interpretarse con **extrema cautela** debido a limitaciones estad√≠sticas fundamentales:

| M√©trica | Valor | Implicaci√≥n |
|---------|-------|-------------|
| Mujeres en muestra | 291 (5.0%) | **Subrepresentaci√≥n severa** |
| Hombres en muestra | 5,507 (95.0%) | Muestra dominante |
| Poder estad√≠stico | Bajo | Dif√≠cil detectar efectos sutiles |
| Representatividad | Cuestionable | ¬øSon estas 291 representativas? |

### ¬øPor Qu√© Esto Importa?

#### 1. **Problema de Poder Estad√≠stico**

Con solo 291 mujeres:
- **Intervalos de confianza amplios:** Nuestro estimado de -$12,442 tiene alta incertidumbre
- **Varianza subestimada:** Si las mujeres var√≠an mucho entre s√≠ (ej. junior vs senior), 291 observaciones capta mal esa heterogeneidad
- **Efectos sutiles invisibles:** Variables como "tipo de empresa" o "capacidad de negociaci√≥n" que podr√≠an explicar parte de la brecha quedan sin detectar

#### 2. **Sesgo de Selecci√≥n Potencial**

¬øQui√©nes son estas 291 mujeres que respondieron?

**Escenarios posibles:**

- **Sesgo de supervivencia:** ¬øSon las mujeres que "sobrevivieron" en tech? Las que ya salieron del sector por discriminaci√≥n no est√°n en la muestra.
- **Auto-selecci√≥n:** ¬øMujeres en posiciones m√°s visibles/senior respondieron m√°s? Esto subestimar√≠a la brecha.
- **Efecto opuesto:** ¬øMujeres frustradas con salarios bajos buscaron m√°s la encuesta? Esto sobrestimar√≠a la brecha.

No podemos saber cu√°l sesgo domina sin datos de representatividad de la muestra.

#### 3. **Incapacidad del Modelo Multivariado**

**Hallazgo t√©cnico:** La variable `female` fue **autom√°ticamente removida** del modelo completo por "baja varianza".

**Explicaci√≥n:**
- Con 95% hombres, g√©nero tiene casi cero variaci√≥n
- Causa **multicolinealidad** (la variable es casi constante)
- El algoritmo no puede calcular error est√°ndar confiable

**Implicaci√≥n:** El modelo multivariado NO PUEDE responder preguntas sofisticadas como:
- "¬øLa brecha persiste controlando por actividades espec√≠ficas?"
- "¬øEs mayor en ciertas ciudades?"
- "¬øCambi√≥ con la pandemia para mujeres vs hombres?"

### Lo Que S√ç Podemos Decir con Certeza

A pesar de limitaciones, hay hechos robustos:

1. **La subrepresentaci√≥n es real:** 5% mujeres vs ~50% poblaci√≥n es desbalance extremo
2. **Existe una brecha observable:** -$12,442 MXN ajustada por experiencia (p<0.001)
3. **La brecha no es atribuible a experiencia:** Las mujeres tienen experiencia promedio similar (~10 a√±os)
4. **El problema es estructural:** No es un "artefacto estad√≠stico" - la diferencia es clara en los datos

### Lo Que NO Podemos Afirmar

- **Magnitud exacta:** El -$12,442 tiene intervalo de confianza amplio
- **Mecanismos causales espec√≠ficos:** ¬øEs discriminaci√≥n directa? ¬øSegregaci√≥n ocupacional? ¬øDiferencias de negociaci√≥n? No podemos separar con estos datos.
- **Heterogeneidad:** ¬øTodas las mujeres sufren la brecha igual? ¬øVar√≠a por ciudad/rol/industria?
- **Tendencias temporales:** ¬øMejora o empeora? 291 mujeres no permiten an√°lisis a√±o por a√±o robusto.

### Reflexi√≥n sobre el Mercado Mexicano

**El hallazgo m√°s importante NO es la brecha salarial, sino la representaci√≥n extrema.**

#### Implicaciones para Pol√≠tica P√∫blica e Industria:

1. **Pipeline problem:** 5% sugiere filtros en:
   - Educaci√≥n superior (pocas mujeres en carreras CS/Ingenier√≠a)
   - Entrada al mercado (discriminaci√≥n en contrataci√≥n inicial)
   - Retenci√≥n (salida de mujeres mid-career por ambiente hostil)

2. **C√≠rculo vicioso:**
   ```
   Pocas mujeres en tech 
   ‚Üí Falta de modelos a seguir 
   ‚Üí Pocas estudiantes eligen carrera
   ‚Üí Pocas candidatas 
   ‚Üí "No encontramos mujeres calificadas"
   ‚Üí Se refuerza status quo
   ```

3. **Imposibilidad de an√°lisis granular:**
   - No podemos hacer benchmarks salariales confiables por subespecialidad
   - Dif√≠cil identificar empresas/roles con mejores pr√°cticas de equidad
   - Pol√≠ticas de diversidad carecen de datos para medir efectividad

#### Recomendaciones

**Para Investigaci√≥n Futura:**
- Sobremuestrear intencionalmente mujeres en tech (m√≠nimo 500-1000)
- Estudios cualitativos: ¬øPor qu√© tan pocas mujeres en muestra?
- An√°lisis longitudinal: Seguir cohortes desde universidad

**Para la Industria:**
- **Transparencia salarial:** Bandas salariales p√∫blicas por rol (reduce asimetr√≠a de informaci√≥n en negociaci√≥n)
- **Auditor√≠as de equidad:** An√°lisis internos con datos completos de la empresa
- **Programas de pipeline:** Bootcamps, becas, mentor√≠as para mujeres

**Para Individuos:**
- **Mujeres en tech:** Negociar agresivamente, cambiar de empresa si hay brecha
- **Aliados hombres:** Transparencia con colegas sobre salarios, referir activamente mujeres

---

## Limitaciones

### 1. **Datos Observacionales, No Experimentales**

Los coeficientes representan **asociaciones causales ajustadas**, no causalidad pura de un experimento aleatorizado. Siempre existe riesgo de **confusi√≥n residual** por variables no medidas.

**Ejemplos de confusores potenciales:**
- Tama√±o de empresa (correlacionado con salario, no medido bien)
- Tipo de empresa (producto vs outsourcing, solo parcialmente capturado)
- Habilidades blandas (negociaci√≥n, liderazgo)
- Timing de entrada a empresa (antes/despu√©s de funding)

### 2. **Salarios Auto-Reportados**

- **Sesgo de recuerdo:** Personas podr√≠an no recordar salario exacto
- **Sesgo de deseabilidad social:** Sobreestimar/subestimar estrat√©gicamente
- **Desviaci√≥n inflacionaria:** Respuestas en momentos diferentes del a√±o

### 3. **Sesgo de Selecci√≥n en Survey**

¬øQui√©n responde encuestas de salarios?
- Personas activamente interesadas en benchmark (¬øbuscan cambio?)
- Usuarios de plataformas tech espec√≠ficas (m√°s activos en comunidad)
- Potencialmente subrepresenta trabajadores muy senior/muy junior

### 4. **Multicolinealidad entre Variables**

Muchas variables est√°n correlacionadas (ej. experiencia‚Üîroles senior‚Üîsalario alto), dificultando atribuir efectos 100% independientes. Usamos regresi√≥n en lugar de matching por limitaciones computacionales, pero matching podr√≠a dar estimados m√°s robustos.

### 5. **Heterogeneidad de Tratamiento**

Los efectos reportados son **promedios**. El efecto de "aprender Go" podr√≠a ser +$15k para algunos, 0 para otros. No modelamos estas interacciones por parsimonia.

### 6. **Temporal: 2020-2022 es Per√≠odo At√≠pico**

Pandemia gener√≥:
- Volatilidad salarial inusual
- Cambios estructurales en trabajo remoto
- Inflaci√≥n acelerada
- Resultados pueden no generalizar a mercado "normal"

---

## Para Practicantes de ML: Tu Camino de Aprendizaje en Causal Inference

Si este an√°lisis te ha interesado y quieres profundizar en la diferencia entre predicci√≥n y causalidad, aqu√≠ est√° tu roadmap.

### üéØ Preguntas Clave que Ahora Puedes Hacerte

**Antes (pensamiento ML predictivo):**
- "¬øQu√© tan bien puedo predecir Y dado X?"
- "¬øQu√© features tienen mayor importancia?"
- "¬øMi modelo generaliza a test set?"

**Despu√©s (pensamiento causal):**
- "¬øQu√© pasa si cambio X? ¬øCu√°nto cambia Y?"
- "¬øEsta correlaci√≥n es espuria o causal?"
- "¬øQu√© variables debo controlar y cu√°les NO?"
- "¬øPuedo identificar efectos causales con datos observacionales?"

### üìö Recursos Recomendados (Orden Sugerido)

#### **Nivel 1: Fundamentos Conceptuales**

**Para ML practitioners que empiezan:**

1. **"Causal Inference for Data Science"** - Brian Calloway (O'Reilly)
   - Escrito espec√≠ficamente para audiencia DS/ML
   - Muchos ejemplos pr√°cticos en Python
   - Bridge perfecto entre ML y causalidad

2. **"Causal Inference: The Mixtape"** - Scott Cunningham (free online)
   - Muy accesible, con c√≥digo en R/Python/Stata
   - Enfoque econ√≥mico pero generalizable
   - Disponible gratis: [mixtape.scunning.com](https://mixtape.scunning.com)

3. **"The Book of Why"** - Judea Pearl (divulgaci√≥n)
   - No t√©cnico, excelente para intuici√≥n
   - Introduce DAGs y do-calculus conceptualmente
   - Lectura de fin de semana

#### **Nivel 2: T√©cnico pero Accesible**

4. **"Mostly Harmless Econometrics"** - Angrist & Pischke
   - Biblia de causal inference aplicada
   - No requiere background de econom√≠a
   - Enfoque: identificaci√≥n pr√°ctica con datos observacionales

5. **Curso: "A Crash Course in Causality"** - Jason Roy (Coursera)
   - 5 semanas, muy bien estructurado
   - Cubre: confounding, propensity scores, DAGs, sensitivity analysis
   - Incluye assignments pr√°cticos

#### **Nivel 3: Causal ML (Estado del Arte)**

6. **"Causal Inference for Statistics, Social, and Biomedical Sciences"** - Imbens & Rubin
   - M√°s t√©cnico, marco de "potential outcomes"
   - Fundamental para entender ATE, CATE, etc.

7. **Papers Clave:**
   - Athey & Imbens (2016): "Recursive Partitioning for Heterogeneous Causal Effects"
   - Chernozhukov et al. (2018): "Double/Debiased Machine Learning"
   - K√ºnzel et al. (2019): "Metalearners for Estimating Heterogeneous Treatment Effects"

8. **Librer√≠as Python:**
   ```python
   # Microsoft EconML: Heterogeneous treatment effects
   from econml.dml import CausalForestDML
   
   # Uber CausalML: Uplift modeling
   from causalml.inference.meta import XGBTRegressor
   
   # Microsoft DoWhy: DAG-based causal inference
   import dowhy
   ```

### üî¨ Proyectos Pr√°cticos para Aprender Haciendo

#### **Proyecto 1: Re-analiza un modelo predictivo con lente causal**

Toma un proyecto ML anterior donde predijiste outcome Y con features X:

```python
# Tu modelo predictivo anterior
model = RandomForestRegressor()
model.fit(X, y)
print(f"R¬≤ en test: {model.score(X_test, y_test)}")  # Ej: 0.78
feature_importances = model.feature_importances_

# Ahora hazte preguntas causales:
# 1. ¬øCu√°les features son confounders vs mediadores vs coliders?
# 2. ¬øEl feature "m√°s importante" causa Y o solo predice?
# 3. ¬øPuedo dibujar un DAG de mis variables?
# 4. ¬øQu√© pasa si intervengo en top feature? ¬øY realmente aumentar√°?
```

**Output esperado:** Documento explicando qu√© efectos son (probablemente) causales vs puramente predictivos.

#### **Proyecto 2: Replica un an√°lisis de este repo**

Elige una variable de este an√°lisis (ej: ingl√©s, remoto) y:

1. Dibuja el DAG completo de esa variable
2. Justifica qu√© controlar y qu√© no
3. Corre regresi√≥n con controles
4. Compara con regresi√≥n sin controles (cuantifica el bias)
5. Discute supuestos de identificaci√≥n

#### **Proyecto 3: A/B test retrospectivo con DiD**

Si tienes datos temporales de alg√∫n "treatment" (ej: feature launch, pol√≠tica nueva):

```python
# En vez de comparar post-treatment effect:
treated_post = df[(df.group=='treatment') & (df.period=='post')]['outcome'].mean()
control_post = df[(df.group=='control') & (df.period=='post')]['outcome'].mean()
effect_naive = treated_post - control_post  # ‚úó Sesgado si grupos diferentes

# Usa DiD:
did = (treated_post - treated_pre) - (control_post - control_pre)  # ‚úì Elimina diferencias pre-existentes
```

### üéì Conceptos Clave para Dominar

**Si solo aprendes 5 cosas:**

1. **Confounding ‚â† Multicollinearity**
   - Multicollinearity (ML): Variables muy correlacionadas ‚Üí inferencia inestable
   - Confounding (Causal): Variable que causa X e Y ‚Üí bias en efecto de X‚ÜíY

2. **DAGs son tu mejor amigo**
   - Representan asunciones causales expl√≠citamente
   - Determinan qu√© controlar (backdoor criterion)
   - Testean qu√© modelos son identificables

3. **do(X=x) ‚â† see(X=x)**
   - P(Y | X=x): "Probabilidad de Y dado que observo X=x" (predictivo)
   - P(Y | do(X=x)): "Probabilidad de Y si SETEO X=x interviniendo" (causal)
   - Solo el segundo responde "¬øqu√© pasa si cambio X?"

4. **Identificaci√≥n > Estimaci√≥n**
   - ML: "¬øQu√© algoritmo minimiza error?" (estimaci√≥n)
   - Causal: "¬øPuedo identificar el efecto causal con estos datos?" (identificaci√≥n)
   - Si identificaci√≥n falla, no importa qu√© algoritmo uses

5. **R¬≤ es irrelevante para validez causal**
   - Alta correlaci√≥n ‚â† causalidad
   - Modelo simple bien identificado > modelo complejo mal identificado
   - En causalidad: Prioriza interpretabilidad y supuestos expl√≠citos

### ü§î Cu√°ndo Usar Cada Enfoque

| Pregunta | Enfoque | Herramientas |
|----------|---------|--------------|
| "¬øQu√© salario tiene X?" | **Predictivo (ML)** | XGBoost, Neural Networks, Feature engineering |
| "¬øQu√© pasa si cambio X?" | **Causal** | Regresi√≥n con controles, IV, RDD, DiD |
| "¬øA qui√©n targeting para intervenci√≥n?" | **Causal ML (CATE)** | Causal Forests, Meta-learners, Double ML |
| "¬øCu√°nto impact√≥ campa√±a?" | **Causal experimental** | A/B test, switchback experiments |
| "¬øQu√© features importan?" | **Depende del 'por qu√©'** | ML si predictivo, Causal si intervenci√≥n |

### üí° Reflexi√≥n Final: El Tri√°ngulo del ML Pr√°ctico

```
          DESCRIPTIVO
         /     |     \
        /      |      \
       /       |       \
  PREDICTIVO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CAUSAL
      ‚Üì                ‚Üì
   "¬øQu√© pasar√°?"  "¬øQu√© debo hacer?"
```

**La mayor√≠a del ML se enfoca en Predictivo.**  
**Los mejores data scientists dominan los 3.**

- **Descriptivo:** Entender qu√© pas√≥ (EDA, dashboards)
- **Predictivo:** Anticipar qu√© pasar√° (forecasting, clasificaci√≥n)
- **Causal:** Decidir qu√© hacer para cambiar outcomes (intervenciones, policy)

**Este an√°lisis es primariamente causal con elementos descriptivos.**

Si trabajas en:
- **Product analytics:** Necesitas causal (A/B test interpretation)
- **Growth:** Necesitas causal (uplift modeling, attribution)
- **Strategy:** Necesitas causal (escenarios "what-if")
- **Forecasting puro:** Predictivo es suficiente

---

## Reproducci√≥n

### Requisitos

```bash
python >= 3.12
pandas >= 2.3.3
numpy >= 1.26.4
matplotlib >= 3.10.8
seaborn >= 0.13.2
scikit-learn >= 1.8.0
scipy >= 1.12.0
```

### Instalaci√≥n

```bash
# Clonar repositorio
git clone <repo-url>
cd salarios-notebook

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate  # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### Generar An√°lisis

```bash
# Ejecutar notebook completo
jupyter notebook causal_analysis.ipynb

# Las figuras se generar√°n en el directorio figures/
```

### Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ answers-2020.csv           # Datos encuesta 2020
‚îú‚îÄ‚îÄ answers-2021.csv           # Datos encuesta 2021
‚îú‚îÄ‚îÄ answers-2022.csv           # Datos encuesta 2022
‚îú‚îÄ‚îÄ causal_analysis.ipynb      # Notebook principal
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias Python
‚îú‚îÄ‚îÄ figures/                   # Visualizaciones generadas
‚îÇ   ‚îú‚îÄ‚îÄ 01_experiencia.png
‚îÇ   ‚îú‚îÄ‚îÄ 02_ingles.png
‚îÇ   ‚îú‚îÄ‚îÄ 03_genero.png
‚îÇ   ‚îú‚îÄ‚îÄ 04_ciudades.png
‚îÇ   ‚îú‚îÄ‚îÄ 05_lenguajes.png
‚îÇ   ‚îî‚îÄ‚îÄ 06_modelo_multivariado.png
‚îî‚îÄ‚îÄ README.md                  # Este archivo
```

---

## Licencia y Permisos

### Uso de los Datos

Estos datos provienen de las encuestas de salarios de Software Guru y est√°n sujetos a las siguientes restricciones:

**Permitido:**
- ‚úÖ Uso para prop√≥sitos acad√©micos o de investigaci√≥n personal
- ‚úÖ An√°lisis y visualizaciones para comprensi√≥n del mercado
- ‚úÖ Compartir hallazgos de forma agregada (no datos individuales)

**NO Permitido:**
- ‚ùå Generar estad√≠sticas para perfiles que busca espec√≠ficamente tu empresa o cliente
- ‚ùå Generar reportes comerciales para la empresa donde trabajas o tus clientes
- ‚ùå Uso comercial de cualquier tipo sin autorizaci√≥n

**Para uso comercial:** Contacta a **talento@sg.com.mx** para contratar un plan de acceso completo a los datos (este repositorio solo incluye una parte de los datos disponibles).

### C√≥digo del An√°lisis

El c√≥digo de este repositorio (notebooks, scripts) est√° bajo licencia MIT - ver archivo LICENSE para detalles.

---

## Citaci√≥n
